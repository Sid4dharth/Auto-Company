# Experimental Design Checklist

## Research Question Formulation

### Is the Question Well-Formed?
- [ ] **Specific:** Clearly defined variables and relationships
- [ ] **Answerable:** Can be addressed with available methods
- [ ] **Relevant:** Addresses a gap in knowledge or practical need
- [ ] **Feasible:** Resources, time, and ethical considerations allow it
- [ ] **Falsifiable:** Can be proven wrong if incorrect

### Have You Reviewed the Literature?
- [ ] Identified what's already known
- [ ] Found gaps or contradictions to address
- [ ] Learned from methodological successes and failures
- [ ] Identified appropriate outcome measures
- [ ] Determined typical effect sizes in the field

## Hypothesis Development

### Is Your Hypothesis Testable?
- [ ] Makes specific, quantifiable predictions
- [ ] Variables are operationally defined
- [ ] Specifies direction/nature of expected relationships
- [ ] Can be falsified by potential observations

### Types of Hypotheses
- [ ] **Null hypothesis (H₀):** No effect/relationship exists
- [ ] **Alternative hypothesis (H₁):** Effect/relationship exists
- [ ] **Directional vs. non-directional:** One-tailed vs. two-tailed tests

## Study Design Selection

### What Type of Study is Appropriate?

**Experimental (Intervention) Studies:**
- [ ] **Randomized Controlled Trial (RCT):** Gold standard for causation
- [ ] **Quasi-experimental:** Non-random assignment but manipulation
- [ ] **Within-subjects:** Same participants in all conditions
- [ ] **Between-subjects:** Different participants per condition
- [ ] **Factorial:** Multiple independent variables
- [ ] **Crossover:** Participants receive multiple interventions sequentially

**Observational Studies:**
- [ ] **Cohort:** Follow groups over time
- [ ] **Case-control:** Compare those with/without outcome
- [ ] **Cross-sectional:** Snapshot at one time point
- [ ] **Ecological:** Population-level data

**Consider:**
- [ ] Can you randomly assign participants?
- [ ] Can you manipulate the independent variable?
- [ ] Is the outcome rare (favor case-control) or common?
- [ ] Do you need to establish temporal sequence?
- [ ] What's feasible given ethical, practical constraints?

## Variables

### Independent Variables (Manipulated/Predictor)
- [ ] Clearly defined and operationalized
- [ ] Appropriate levels/categories chosen
- [ ] Manipulation is sufficient to test hypothesis
- [ ] Manipulation check planned (if applicable)

### Dependent Variables (Outcome/Response)
- [ ] Directly measures the construct of interest
- [ ] Validated and reliable measurement
- [ ] Sensitive enough to detect expected effects
- [ ] Appropriate for statistical analysis planned
- [ ] Primary outcome clearly designated

### Control Variables
- [ ] **Confounding variables identified:**
  - Variables that affect both IV and DV
  - Alternative explanations for findings
- [ ] **Strategy for control:**
  - Randomization
  - Matching
  - Stratification
  - Statistical adjustment
  - Restriction (inclusion/exclusion criteria)
  - Blinding

### Extraneous Variables
- [ ] Potential sources of noise identified
- [ ] Standardized procedures to minimize
- [ ] Environmental factors controlled
- [ ] Time of day, setting, equipment standardized

## Sampling

### Population Definition
- [ ] **Target population:** Who you want to generalize to
- [ ] **Accessible population:** Who you can actually sample from
- [ ] **Sample:** Who actually participates
- [ ] Difference between these documented

### Sampling Method
- [ ] **Probability sampling (preferred for generalizability):**
  - Simple random sampling
  - Stratified sampling
  - Cluster sampling
  - Systematic sampling
- [ ] **Non-probability sampling (common but limits generalizability):**
  - Convenience sampling
  - Purposive sampling
  - Snowball sampling
  - Quota sampling

### Sample Size
- [ ] **A priori power analysis conducted**
  - Expected effect size (from literature or pilot)
  - Desired power (typically .80 or .90)
  - Significance level (typically .05)
  - Statistical test to be used
- [ ] Accounts for expected attrition/dropout
- [ ] Sufficient for planned subgroup analyses
- [ ] Practical constraints acknowledged

### Inclusion/Exclusion Criteria
- [ ] Clearly defined and justified
- [ ] Not overly restrictive (limits generalizability)
- [ ] Based on theoretical or practical considerations
- [ ] Ethical considerations addressed
- [ ] Documented and applied consistently

## Blinding and Randomization

### Randomization
- [ ] **What is randomized:**
  - Participant assignment to conditions
  - Order of conditions (within-subjects)
  - Stimuli/items presented
- [ ] **Method of randomization:**
  - Computer-generated random numbers
  - Random number tables
  - Coin flips (for very small studies)
- [ ] **Allocation concealment:**
  - Sequence generated before recruitment
  - Allocation hidden until after enrollment
  - Sequentially numbered, sealed envelopes (if needed)
- [ ] **Stratified randomization:**
  - Balance important variables across groups
  - Block randomization to ensure equal group sizes
- [ ] **Check randomization:**
  - Compare groups at baseline
  - Report any significant differences

### Blinding
- [ ] **Single-blind:** Participants don't know group assignment
- [ ] **Double-blind:** Participants and researchers don't know
- [ ] **Triple-blind:** Participants, researchers, and data analysts don't know
- [ ] **Blinding feasibility:**
  - Is true blinding possible?
  - Placebo/sham controls needed?
  - Identical appearance of interventions?
- [ ] **Blinding check:**
  - Assess whether blinding maintained
  - Ask participants/researchers to guess assignments

## Control Groups and Conditions

### What Type of Control?
- [ ] **No treatment control:** Natural course of condition
- [ ] **Placebo control:** Inert treatment for comparison
- [ ] **Active control:** Standard treatment comparison
- [ ] **Wait-list control:** Delayed treatment
- [ ] **Attention control:** Matches contact time without active ingredient

### Multiple Conditions
- [ ] Factorial designs for multiple factors
- [ ] Dose-response relationship assessment
- [ ] Mechanism testing with component analyses

## Procedures

### Protocol Development
- [ ] **Detailed, written protocol:**
  - Step-by-step procedures
  - Scripts for standardized instructions
  - Decision rules for handling issues
  - Data collection forms
- [ ] Pilot tested before main study
- [ ] Staff trained to criterion
- [ ] Compliance monitoring planned

### Standardization
- [ ] Same instructions for all participants
- [ ] Same equipment and materials
- [ ] Same environment/setting when possible
- [ ] Same assessment timing
- [ ] Deviations from protocol documented

### Data Collection
- [ ] **When collected:**
  - Baseline measurements
  - Post-intervention
  - Follow-up timepoints
- [ ] **Who collects:**
  - Trained researchers
  - Blinded when possible
  - Inter-rater reliability established
- [ ] **How collected:**
  - Valid, reliable instruments
  - Standardized administration
  - Multiple methods if possible (triangulation)

## Measurement

### Validity
- [ ] **Face validity:** Appears to measure construct
- [ ] **Content validity:** Covers all aspects of construct
- [ ] **Criterion validity:** Correlates with gold standard
  - Concurrent validity
  - Predictive validity
- [ ] **Construct validity:** Measures theoretical construct
  - Convergent validity (correlates with related measures)
  - Discriminant validity (doesn't correlate with unrelated measures)

### Reliability
- [ ] **Test-retest:** Consistent over time
- [ ] **Internal consistency:** Items measure same construct (Cronbach's α)
- [ ] **Inter-rater reliability:** Agreement between raters (Cohen's κ, ICC)
- [ ] **Parallel forms:** Alternative versions consistent

### Measurement Considerations
- [ ] Objective measures preferred when possible
- [ ] Validated instruments used when available
- [ ] Multiple measures of key constructs
- [ ] Sensitivity to change considered
- [ ] Floor/ceiling effects avoided
- [ ] Response formats appropriate
- [ ] Recall periods appropriate
- [ ] Cultural appropriateness considered

## Bias Minimization

### Selection Bias
- [ ] Random sampling when possible
- [ ] Clearly defined eligibility criteria
- [ ] Document who declines and why
- [ ] Minimize self-selection

### Performance Bias
- [ ] Standardized protocols
- [ ] Blinding of providers
- [ ] Monitor protocol adherence
- [ ] Document deviations
